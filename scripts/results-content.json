[
  "efficiency trade off.\nTo conclude, this analysis of the quadrant provides the most complete validation of the re-\nsearch.  It shows that an intelligent routing layer with a combination of a carefully engineered\nprompts  are  not  just  incremental  improvements.   They  are  part  of  a  transformative  strategy\nof optimization.   By using carefully designed instructions to guide a smaller,  more efficient\n8B model, the system achieves a performance profile that rivals a modelnearlyt twice its size,\nbut at a fraction of the computational and energy costs.  This goes to show that architectural\nand instructional refinement can be a more sustainable and effective approach to high perfor-\nmance,rather than simply scaling up the model size.\n7    Experimental Consistency and Reproducibility\nTo guarantee that the performance and energy consumption results represented in this thesis\nare  both  valid  and  reliable,  a  strict  protocol  was  established  to  try  to  minimize  the  number\nof  variables  and  create  a  consistent  testing  environment  for  all  experiments.   The  following\nmeasures  were  systematically  implemented  to  ensure  that  the  results  sh",
  "own  can  be  directly\nattributed to the changes in the system’s instruction design and model performance.\nFirst, the test system was maintained in a controlled and isolated state. To prevent interfer-\nence from many background tasks associated with other programs, and also with the operating\nsystem tasks, such as automatic updates or network-related tasks, the machine’s internet con-\nnection was physically disabled for the duration of all test runs. To further improve repeatability,\nprior to initiating any experiment, all non-essential background applications and services were\nfully terminated.  The system was then left without any intervention after the scripts started up\nuntil they were finished and all the required data was collected. This ensured that the system’s\ncomputational resources were devoted exclusively to the experimental workload.\nAnother point taken to maintain the system repeatability was that a static software envi-\nronment  was  kept  during  the  entire  research  process.   The  main  components  of  the  system,\nincluding the Python interpreter, the PyCharm IDE, and the HWiNFO monitoring utility, were\nnot updated after the initial setup. This strategy is crucial to eliminate the risk of major software\nupdates introducing performance variations that could skew the results.\nFinally,  and  most  critically,  the  underlying  code  base  for  the  query-routing  system  and\nmodel inference remained identical across all comparative experiments.  When testing the ef-\nficacy of different instructions, the sole modification between each run was the content of the\nsystem instruction itself.  This strict isolation of the",
  "independent variable ensures that all mea-\nsured differences in answer accuracy, latency and energy consumption are direct consequences\nof the prompt engineering strategy, rather than unintended changes in the software that supports\nit.",
  "Challenges and Abandoned Approaches\nIn the course of this research, some promising strategies were explored but ultimately aban-\ndoned due to practical constraints, resource limitations, or conflicts with the project’s core ob-\njectives.  This section represents these methodological dead ends, as understanding what these\nwere and their causes could aid further research.\nOne of the initial strategies considered for enhancing the RAG component was the usage of\na hypothetical document similar to HyDE[40]. The technique, which involves generating a hy-\npothetical answer to a query to improve the semantic search for relevant documents, has shown\npromise in other projects. However, the original HyDE (Answer RQ2) paper recommended the\ngeneration of up to eight hypothetical documents per retrieval to achieve optimal performance.\nIn practice,  this approach proved to be prohibitively expensive for the presented framework.\nThe computational overhead of generating eight separate documents before the retrieval was\ndone and the formation of the final answer would have dramatically increased both energy con-\nsumption and latency,  with the latter representing a change that would make the framework\nbasically unusable with the current hardware. This would directly undermine the primary goal\nof creating a fast and efficient system for resource-constrained environments.\nAnother considered approach was the us"
]